{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "# load important packages\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import scipy.stats\n",
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stimuli import events2neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load subject_class.py\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class subject(object):\n",
    "    \"\"\"try to organize data based on subject ex sub001\"\"\"\n",
    "    def __init__(self,sub):\n",
    "        # subject info ex: 'sub001'\n",
    "        self.sub_id = sub\n",
    "\n",
    "        # BOLD folder for this subject\n",
    "        sub_BOLD_path = \"../data/ds105/%s/BOLD/\" %self.sub_id\n",
    "\n",
    "        # anatomy folder for this subject\n",
    "        sub_anatomy_file = \"../data/ds105/%s/anatomy/highres001_brain.nii.gz\" %self.sub_id\n",
    "        \n",
    "        # runfile_list: ['task001_run001', 'task001_run002'......]\n",
    "        runfile_list = ['task001_run'+ i+ '.txt' for i in ['001','002','003','004','005','006','007','008','009','010','011','012']]\n",
    "        runlist = ['run'+ i for i in ['001','002','003','004','005','006','007','008','009','010','011','012']]\n",
    "        \n",
    "        # TR info:\n",
    "        self.TR = 2.5\n",
    "        \n",
    "        # load high resolution brain structure for this subject\n",
    "        self.brain_img = nib.load(sub_anatomy_file)\n",
    "        \n",
    "        # load all bold image file for this subject\n",
    "        self.run_img_result = {}\n",
    "        for i in runlist:\n",
    "            self.run_img_result[self.sub_id + '_' + i] = nib.load(sub_BOLD_path+'task001_'+i+'/bold.nii.gz')\n",
    "        \n",
    "        # all run keys:\n",
    "        self.run_keys = self.run_img_result.keys()\n",
    "\n",
    "        # shape of the BOLD data:\n",
    "        self.BOLD_shape = self.run_img_result[self.run_keys[1]].shape\n",
    "        \n",
    "        # conditions setting: which condition is for which category\n",
    "        self.condition_key_file = open(\"../data/ds105/models/model001/condition_key.txt\")\n",
    "        condition_list = self.condition_key_file.readlines()\n",
    "        condition = re.compile(r'(cond\\d+) (\\w+)')\n",
    "        result = {}\n",
    "        for item in condition_list:\n",
    "            for match in condition.finditer(item):\n",
    "                result[match.group(1)] = match.group(2)\n",
    "        self.condition_key = result\n",
    "        \n",
    "        # condition files for each objects for each run\n",
    "        sub_condition_path = \"../data/ds105/%s/model/model001/onsets/\" %self.sub_id\n",
    "        self.conditions = {}\n",
    "        for i in runfile_list:\n",
    "            for j in self.condition_key.keys():\n",
    "                self.conditions[i[8:14]+'-'+self.condition_key[j]] = sub_condition_path + i[:-4]+'/'+j+'.txt'\n",
    "                   \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/edithho/Google Drive/cal/2015 fall/stat159/project-zeta/experimental'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../data/ds105/sub001/anatomy/highres001_brain.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5e760b7d64bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sub001\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Loop this for other subjects...LATER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-b5a407879087>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sub)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# load high resolution brain structure for this subject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrain_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_anatomy_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# load all bold image file for this subject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/nibabel/loadsave.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m        \u001b[0mImage\u001b[0m \u001b[0mof\u001b[0m \u001b[0mguessed\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     '''\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mguessed_image_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/nibabel/loadsave.pyc\u001b[0m in \u001b[0;36mguessed_image_type\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinc2Image\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'\\211HDF'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mMinc1Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.nii'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mBinOpener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbinaryblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m348\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhich_analyze_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinaryblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/nibabel/openers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fileish, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'compresslevel'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_names\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'compresslevel'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compresslevel'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_compresslevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mme_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/nibabel/openers.pyc\u001b[0m in \u001b[0;36m_gzip_open\u001b[0;34m(fileish, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# open gzip files with faster reads on large files using larger chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# See https://github.com/nipy/nibabel/pull/210 for discussion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mgzip_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mgzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_read_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGZIP_MAX_READ_CHUNK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgzip_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBufferedIOBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Issue #13781: os.fdopen() creates a fileobj with a bogus name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../data/ds105/sub001/anatomy/highres001_brain.nii.gz'"
     ]
    }
   ],
   "source": [
    "sub1 = subject(\"sub001\") # Loop this for other subjects...LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub1.BOLD_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub1.TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub1.brain_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub1.condition_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub1_condition_files = sub1.conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub1_condition_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub1.sub_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load get_object_neural.py\n",
    "\n",
    "def get_object_neural(sub_ID ,condition_dict, object_name, TR, n_vox, check = 0, ):\n",
    "    \"\"\"\n",
    "    get object neural array for specific object from all runs, odd runs or even runs\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    condition_dict: dictionary of all condition files\n",
    "    object_name: desired object name: 'house','scrambledpix','cat','shoe','bottle','scissors','chair','face'\n",
    "    TR: TR for fMRI\n",
    "    n_vox: time course of fMRI\n",
    "    check: 1= odd runs, 2=even runs, others = all runs\n",
    "    \n",
    "    output\n",
    "    -------\n",
    "    a dictionary of run name : (neural array, path of the bold image) for that run\n",
    "    ex:\n",
    "    \n",
    "    {\n",
    "    'run001-bottle-neural': (array([ 0.,  0.,  0.,  0.,  0., ...]), bold path)\n",
    "    'run002-bottle-neural': (array([ 0.,  0.,  0.,  0.,  0., ...]), bold path)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    condition_dict_key = condition_dict.keys()\n",
    "    result = {}\n",
    "    for i in condition_dict_key:\n",
    "        if check == 1:\n",
    "            if object_name in i:\n",
    "                if int(i[3:6])%2 ==1:\n",
    "                    result[i+'-neural'] = (events2neural(condition_dict[i], TR, n_vox), \"../data/ds105/%s/BOLD/task001_\"% sub_ID + i[:6]+\"/bold.nii.gz\")\n",
    "        elif check == 2:\n",
    "            if object_name in i: \n",
    "                if int(i[3:6])%2 ==0:\n",
    "                    result[i+'-neural'] = (events2neural(condition_dict[i], TR, n_vox), \"../data/ds105/%s/BOLD/task001_\"% sub_ID + i[:6]+\"/bold.nii.gz\")\n",
    "        else:\n",
    "            if object_name in i:\n",
    "                result[i+'-neural'] = (events2neural(condition_dict[i], TR, n_vox), \"../data/ds105/%s/BOLD/task001_\"%sub_ID + i[:6]+\"/bold.nii.gz\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_odd_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"cat\" , sub1.TR, sub1.BOLD_shape[-1], check=1)\n",
    "cat_even_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"cat\" , sub1.TR, sub1.BOLD_shape[-1], check=2)\n",
    "house_odd_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"house\" , sub1.TR, sub1.BOLD_shape[-1], check=1)\n",
    "house_even_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"house\" , sub1.TR, sub1.BOLD_shape[-1], check=2)\n",
    "bottle_odd_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"bottle\" , sub1.TR, sub1.BOLD_shape[-1], check=1)\n",
    "bottle_even_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"bottle\" , sub1.TR, sub1.BOLD_shape[-1], check=2)\n",
    "face_odd_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"face\" , sub1.TR, sub1.BOLD_shape[-1], check=1)\n",
    "face_even_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"face\" , sub1.TR, sub1.BOLD_shape[-1], check=2)\n",
    "scissors_odd_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"scissors\" , sub1.TR, sub1.BOLD_shape[-1], check=1)\n",
    "scissors_even_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"scissors\" , sub1.TR, sub1.BOLD_shape[-1], check=2)\n",
    "shoe_odd_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"shoe\" , sub1.TR, sub1.BOLD_shape[-1], check=1)\n",
    "shoe_even_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"shoe\" , sub1.TR, sub1.BOLD_shape[-1], check=2)\n",
    "scrambledpix_odd_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"scrambledpix\" , sub1.TR, sub1.BOLD_shape[-1], check=1)\n",
    "scrambledpix_even_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"scrambledpix\" , sub1.TR, sub1.BOLD_shape[-1], check=2)\n",
    "chair_odd_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"chair\" , sub1.TR, sub1.BOLD_shape[-1], check=1)\n",
    "chair_even_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"chair\" , sub1.TR, sub1.BOLD_shape[-1], check=2)\n",
    "\n",
    "neuralDict = []\n",
    "for key, value in sub1.condition_key.iteritems():\n",
    "    for i in xrange(1,3):\n",
    "        neuralObj = get_object_neural(sub1.sub_id, sub1.conditions, value, sub1.TR, sub1.BOLD_shape[-1], check = i)\n",
    "        neuralDict.append(neuralObj)\n",
    "        \n",
    "len(neuralDict)\n",
    "#cat_odd_neural = get_object_neural(sub1.sub_id, sub1.conditions,\"cat\" , sub1.TR, sub1.BOLD_shape[-1], check=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_odd_neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_odd_neural['run001-cat-neural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load ObtainData.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "def pull3D(DictionaryOfVectors):\n",
    "\tThree_D_Data = []\n",
    "\tfor key, value in DictionaryOfVectors.iteritems():\n",
    "\t\tvector = value[0]\n",
    "\t\tfileLocation = value[1]\n",
    "\t\timg = nib.load(fileLocation)\n",
    "\t\tdata = img.get_data()\n",
    "\t\tfor i in range(0, len(vector)):\n",
    "\t\t\tif vector[i] == 1:\n",
    "\t\t\t\tThree_D_Data.append(data[:, :, :, i])\n",
    "\treturn Three_D_Data\n",
    "\n",
    "def ShowCortex(ListOf3dImages):\n",
    "\tfor image in ListOf3dImages:\n",
    "\t\tzDimension = np.shape(image)[2]\n",
    "\t\tfor i in range(0, zDimension):\n",
    "\t\t\tplt.imshow(image[:, :, i], cmap = \"gray\")\n",
    "\t\t\tplt.show()\n",
    "\n",
    "# You'll have to guess the Z value from the images show in the previous function\n",
    "def generateEvenlySpacedZpoints(zValue):\n",
    "\treturn np.linspace(start = 0, stop = zValue, num = zValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listof3D = []\n",
    "for neural in neuralDict:\n",
    "    listof3D.append(pull3D(neural))\n",
    "\n",
    "print(len(listof3D))\n",
    "\n",
    "#aa = pull3D(cat_odd_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub1_condition_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c083184a48c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcondList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub1_condition_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcondList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub1_condition_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcondList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sub1_condition_files' is not defined"
     ]
    }
   ],
   "source": [
    "condList = []\n",
    "for key, value in sub1_condition_files.iteritems():\n",
    "    condList.append(sub1_condition_files[key])\n",
    "\n",
    "condList\n",
    "    \n",
    "run1_face_cond = sub1_condition_files['run001-face'] # Loop this\n",
    "run1_face_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run1_face_neural_prediction = events2neural(run1_face_cond, sub1.TR, sub1.BOLD_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x117220790>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tr_times = np.arange(sub1.BOLD_shape[-1]) * sub1.TR\n",
    "plt.plot(all_tr_times, run1_face_neural_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hrf(times):\n",
    "    \"\"\" Return values for HRF at given times \"\"\"\n",
    "    # Gamma pdf for the peak\n",
    "    peak_values = gamma.pdf(times, 6)\n",
    "    # Gamma pdf for the undershoot\n",
    "    undershoot_values = gamma.pdf(times, 12)\n",
    "    # Combine them\n",
    "    values = peak_values - 0.35 * undershoot_values\n",
    "    # Scale max to 0.6\n",
    "    return values / np.max(values) * 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_times = np.arange(0, 30, sub1.TR) # BUT WHY 30\n",
    "hrf_at_trs = hrf(tr_times) \n",
    "len(hrf_at_trs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolved = np.convolve(run1_face_neural_prediction, hrf_at_trs)\n",
    "N = len(run1_face_neural_prediction)  # M == # of volumes == 121\n",
    "M = len(hrf_at_trs)  # M == 12\n",
    "len(convolved) == N + M - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_to_remove = len(hrf_at_trs) - 1\n",
    "convolved = convolved[:-n_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x113dd0350>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(all_tr_times, run1_face_neural_prediction)\n",
    "plt.plot(all_tr_times, convolved)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
